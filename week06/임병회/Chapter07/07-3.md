# 신경망 모델 훈련

## 손실 곡선

```python
# 데이터
from tensorflow import keras
from sklearn.model_selection import train_test_split
(train_input, train_target), (test_input, test_target) =\
  keras.datasets.fashion_mnist.load_data()
train_scaled = train_input / 255.0
train_scaled, val_scaled, train_target, val_target = train_test_split(
    train_scaled, train_target, test_size=0.2, random_state=42
)
# 모델
def model_fn(a_layer=None):
  model=keras.Sequential()
  model.add(keras.layers.Flatten(input_shape=(28,28)))
  model.add(keras.layers.Dense(100, activation='relu'))
  if a_layer:
    model.add(a_layer)
  model.add(keras.layers.Dense(10, activation='softmax'))
  return model
model=model_fn()
model.summary()
# fit 결과 to history
model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_scaled, train_target, epochs=5, verbose=0)
# history 그래프
import matplotlib.pyplot as plt
plt.plot(history.history['loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.show()
```

<img width="470" height="309" alt="image" src="https://github.com/user-attachments/assets/f61902ed-ab04-469e-a674-d23b7210411c" />

```python
# 정확도 출력
plt.plot(history.history['accuracy'])
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.show()
```

<img width="453" height="294" alt="image" src="https://github.com/user-attachments/assets/a142b9e7-64bf-4dd5-9307-20c57fbb5c85" />

## 검증 손실

```python
# 검증 데이터
model=model_fn()
model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history=model.fit(train_scaled, train_target, epochs=20,verbose=0, 
                  validation_data=(val_scaled, val_target))
# 훈련 손실, 검증 손실 그래프
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train', 'val'])
plt.show()
```

<img width="445" height="299" alt="image" src="https://github.com/user-attachments/assets/c895de6a-3652-4e7b-b405-fc7fdaec348f" />

epoch 5 넘어가면 과대적합<br>

```python
#Adam 적용
model=model_fn()
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
history=model.fit(train_scaled, train_target, epoch=20, verbose=0,
                  validation_data=(val_scaled, val_target))
plt.plot(history.histroy['loss'])
plt.plot(history.histroy['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train', 'val'])
plt.show()
```

<img width="506" height="305" alt="image" src="https://github.com/user-attachments/assets/64ed121c-18fc-4ff5-9765-875a5066ec87" />

Adam으로 에포크 늘릴 수 있음<br>

### 학습률 조정해보기

Adam:상대적인 학습 강도 조절<br>
수동:전체 학습 과정의 기본 속도<br>

```python
# 필요한 라이브러리 임포트
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# 1. 데이터 준비
(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()
train_scaled = train_input / 255.0
train_scaled, val_scaled, train_target, val_target = train_test_split(
    train_scaled, train_target, test_size=0.2, random_state=42)

# 2. 모델 생성 함수 정의 (이전과 동일)
def model_fn(a_layer=None):
    model = keras.Sequential()
    model.add(keras.layers.Flatten(input_shape=(28, 28)))
    model.add(keras.layers.Dense(100, activation='relu'))
    if a_layer:
        model.add(a_layer)
    model.add(keras.layers.Dense(10, activation='softmax'))
    return model
# 비교를 위한 기본 학습률 (책의 결과와 동일)
lr_default = 0.001
# 더 높은 학습률
lr_high = 0.01
# 더 낮은 학습률
lr_low = 0.0001

learning_rates = [lr_high, lr_default, lr_low]
histories = {} # 각 학습률별 훈련 기록을 저장할 딕셔너리

for lr in learning_rates:
    # 1. 모델 생성
    model = model_fn()
    
    # 2. Adam 옵티마이저에 학습률 설정
    adam = keras.optimizers.Adam(learning_rate=lr)
    
    # 3. 모델 컴파일
    model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics='accuracy')
    
    # 4. 모델 훈련 (결과를 history에 저장)
    history = model.fit(train_scaled, train_target, epochs=20, verbose=0,
                        validation_data=(val_scaled, val_target))
    
    # 5. 결과 저장
    histories[f'lr={lr}'] = history

# 6. 결과 시각화
plt.figure(figsize=(12, 8))
for name, history in histories.items():
    plt.plot(history.history['val_loss'], label=name)

plt.xlabel('Epoch')
plt.ylabel('Validation Loss')
plt.legend()
plt.title('Validation Loss by Learning Rate')
plt.grid(True)
plt.show()
```

<img width="1009" height="701" alt="image" src="https://github.com/user-attachments/assets/a80ba0cc-0c6f-4a6f-bfff-86e01344a486" />


## 드롭아웃

<img width="318" height="291" alt="image" src="https://github.com/user-attachments/assets/bde21eb0-04ce-49b7-a4b6-1bc0b3664109" />

훈련과정에서 층에 있는 일부 뉴런을 랜덤하게 꺼서 과대적합 방지<br>
훈련 끝난 뒤평가와 예측 시에는 드롭아웃 자동 오프<br>

```python
# 30퍼 드롭아웃
model=model_fn(keras.layers.Dropout(0.3))
model.summary()
# 검증 점수 계산
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
history=model.fit(train_scaled, train_target, epochs=20, verbose=0,
                  validation_data=(val_scaled, val_target))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train', 'val'])
plt.show()
```

<img width="485" height="296" alt="image" src="https://github.com/user-attachments/assets/74f9ae70-c9a8-4832-a476-7dc3eb0cb040" />

과대적합 줄음<br>

## 모델 저장과 복원

```python
# 모델 저장
model=model_fn(keras.layers.Dropout(0.3))
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
history=model.fit(train_scaled, train_target,epochs=10,verbose=0,
                  validation_data=(val_scaled, val_target))
model.save_weights('dropout_weights.h5')
model.save('model-whole.h5')
#훈련하지않은 모델 to model-weght.h5
model=model_fn(keras.layers.Dropout(0.3))
model.load_weights('dropout_weights.h5')
# 모델 전체 읽은 후 정확도 출력
model=keras.models.load_model('model-whole.h5')
model.evalute(val_scaled, val_target)
```

## 콜백

훈련 과정 중간에 어떤 작업을 수행할 수 있게 하는 객체<br>

```python
# 콜백
model=model_fn(keras.layers.Dropout(0.3))
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
checkpoint_cb=keras.callbacks.ModelCheckpoint('best-model.h5', save_best_only=True)
history=model.fit(train_scaled, train_target, epochs=20,verbose=0,
                  validation_data=(val_scaled, val_target),
                  callbacks=[checkpoint_cb])
# 콜백 후 예측
model=keras.models.load_model('best-model.h5')
model.evaluate(val_scaled, val_target)
```

조기종료 - 과대적합 시작 전 훈련 미리 중지<br>

```python
# 조기종료
model=model_fn(keras.layers.Dropout(0.3))
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
checkpoint_cb=keras.callbacks.ModelCheckpoint('best-model.h5', save_best_only=True)
early_stopping_cb=keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)
history=model.fit(train_scaled, train_target, epochs=20,verbose=0,
                  validation_data=(val_scaled, val_target)
                  callbacks=[checkpoint_cb, early_stopping_cb])
# 손실 함수
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train', 'val'])
plt.show()
```

<img width="460" height="300" alt="image" src="https://github.com/user-attachments/assets/6f84ed87-ea8d-4f2d-94de-7a4f3b1b8eee" />

