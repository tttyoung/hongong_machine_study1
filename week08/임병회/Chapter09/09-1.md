

# 순차 데이터와 순환 신경망

## 순차 데이터

순차 데이터 - 순서에 의미가 있는 데이터<br>
시계열 데이터 - 일정간 시간 간격으로 기록된 데이터<br>
피드포워드 신경망 - 입력 데이터의 흐름이 앞으로만 전달되는 신경망<br>

<img width="521" height="321" alt="image" src="https://github.com/user-attachments/assets/35f835c4-25e7-45a6-aeb4-8ca82dbf2754" />

## 순환 신경망

<img width="264" height="353" alt="image" src="https://github.com/user-attachments/assets/30ec6c3a-c37e-4a4b-8720-cee3ef7515e8" />

<img width="367" height="194" alt="image" src="https://github.com/user-attachments/assets/35c43f1a-8221-4812-b295-9577e5847833" />

타임스텝 - 샘플을 처리하는 한 단계<br>
셀 - 순환 신경망에서의 층<br>
은닉 상태 - 셀의 출력<br>

<img width="360" height="228" alt="image" src="https://github.com/user-attachments/assets/72cab040-c4d5-49b2-807d-cdbe71d8c0f4" />

은닉층의 활성화 함수 - tanh 많이 사용<br>

<img width="366" height="309" alt="image" src="https://github.com/user-attachments/assets/3a88a580-a368-4417-8284-b1808c3ec2df" />

왜 tanh 쓸까?<br>
동일한 가중치를 반복 사용하는 구조적 특성 때문에 값이 폭발하는 것을 막아주면서(규제)<->ReLU, 기울기 소실(역전파 시 할성화 함수의 미분값 곱해지는데 sigmoid는 미분값 최대치가 작아 소실된다.)을 최소화해야 하기 때문이다.

은닉상태에도 가중치 곱해져 셀로 들어감<br>

<img width="276" height="268" alt="image" src="https://github.com/user-attachments/assets/ac0fc738-611b-4eca-8f8e-0667205d91d4" />

## 셀의 가중치와 입출력

<img width="272" height="335" alt="image" src="https://github.com/user-attachments/assets/4a254e8f-f78c-4bf3-a1c6-37e5d494d1f2" />

입력층 to 순환층 : 입력층*순환층<br>

<img width="188" height="291" alt="image" src="https://github.com/user-attachments/assets/1bfbdd40-a126-4c93-b674-8a54345f3a3d" />

순환층끼리 : 순환층<sup>2</sup><br>

<img width="501" height="218" alt="image" src="https://github.com/user-attachments/assets/99233028-197d-4952-8312-75fc88365634" />

<img width="691" height="323" alt="image" src="https://github.com/user-attachments/assets/f66ac017-806e-4a32-9788-3119e09d3316" />

