# IMDB 리뷰 분류 by 순환 신경망

원-핫 인코딩 - 특정 단어의 인덱스만 1, 나머지는 모두 0인 1차원 배열<br>
단어 임베딩 - 단어를 실수로 이루어진 벡터로 표현하는 방식, 단어 크기 및 
             단어 간 유사성 반영<br>

## 리뷰 데이터셋

자연어 처리 - 컴퓨터를 사용해 인간의 언어를 처리하는 분야<br>
말뭉치 - 훈련 데이터 in 자연어 처리 분야<br>

<img width="526" height="98" alt="image" src="https://github.com/user-attachments/assets/0a3d7621-f578-43d2-95ff-86c847fb67de" />

토큰 - 위 그림과 같이 분리된 단어, LLM에서는 더 쪼개는 Subword 단위 사용해서
                                데이터 압축<br>

```python
# 문장->정수 데이터
from tensorflow.keras.datasets import imdb
(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words=500)
# 리뷰 1 내용
print(train_input[0])
```

<img width="721" height="360" alt="image" src="https://github.com/user-attachments/assets/3c3d96c4-29f0-42a3-8714-6e020162d8cb" />

```python
# 리뷰 길이, 중간값
import numpy as np
lengths=np.array([len(x) for x in train_input])
print(np.mean(lengths),np.median(lengths))
# 리뷰 길이 히스토그램
import matplotlib.pyplot as plt
plt.hist(lengths)
plt.xlabel('length')
plt.ylabel('frequency')
plt.show()
```

<img width="495" height="295" alt="image" src="https://github.com/user-attachments/assets/229d81c9-870d-480c-b26e-e705c37df847" />

```python
# 길이 100으로 맞추기
from tensorflow.keras.preprocessing.sequence import pad_sequences
train_seq=pad_sequences(train_input, maxlen=100)
print(train_seq.shape)
```

<img width="228" height="238" alt="image" src="https://github.com/user-attachments/assets/0f8236fa-8117-4652-a62d-3558077ea5d8" />

```python
# 자른 샘플 6
print(train_seq[5])
```

<img width="731" height="186" alt="image" src="https://github.com/user-attachments/assets/abc1afd4-191f-4e27-8fe2-22797f49ec44" />

패딩이 앞부분 추가<br>

### 길이 최적 파라미터 구하는법

```python
import numpy as np

# 전체 훈련 데이터의 길이를 구함
lengths = [len(x) for x in train_input]

# 상위 95%에 해당하는 길이를 계산
optimal_maxlen = int(np.percentile(lengths, 95))
print(f"최적 길이: {optimal_maxlen}")

# 이 값으로 패딩 적용
train_seq = pad_sequences(train_input, maxlen=optimal_maxlen)
```

## 순환 신경망 만들기

```python
# 순환 신경망 만들기
from tensorflow import keras
model=keras.Sequential()
model.add(keras.layers.SimpleRNN(8, input_shape=(100,500)))
model.add(keras.layers.Dense(1,activation='sigmoid'))
# 원-핫 인코딩
train_oh=keras.utils.to_categorical(train_seq)
# 검증세트 인코딩
val_oh=keras.utils.to_categorical(val_seq)
```
## 순환 신경망 훈련

```python
# 훈련
rmsprop=keras.optimizers.RMSprop(learning_rate=1e-4)
model.compile(optimizer=rmsprop,loss='binary_crossentropy',metrics=['accuracy'])
checkpoint_cb=keras.callbacks.ModelCheckpoint('best-simplernn-model.h5',
                                              save_best_only=True)
early_stopping_cb=keras.callbacks.EarlyStopping(patience=3,
                                                restore_best_weights=True)
history=model.fit(train_oh, train_target, epochs=100, batch_size=64,
                  validation_data=(val_oh, val_target),
                  callbacks=[checkpoint_cb, early_stopping_cb])
```

## 단어 임베딩

각 단어를 고정된 크기의 실수 벡터로 바꾸어 줌.<br>

<img width="530" height="101" alt="image" src="https://github.com/user-attachments/assets/6464bf1c-bf31-45b6-92d7-cb67a141badd" />

```python
# 임베딩
model12=keras.Sequential()
model12.add(keras.layers.Embedding(500,16,input_length=100))
model12.add(keras.layers.SimpleRNN(8))
model12.add(keras.layers.Dense(1,activation='sigmoid'))
```
