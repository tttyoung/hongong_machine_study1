# 합성곱 신경망의 시각화

## 가중치 시각화

```python
# 로드
from tensorflow import keras
model=keras.models.load_model('best-cnn-model.h5')
# 층 출력
model.layers
# 합성곱층 1 가중치 조사
conv=model.layers[0]
print(conv.weights[0].shape, conv.weights[1].shape)
# 가중치 평균, 표준편차
conv_weights=conv.weights[0].numpy()
print(conv_weights.mean(), conv_weights.std())
# 커널 출력
fig, axs=plt.subplots(2,16,figsize=(15,2))
for i in range(2):
  for j in range(16):
    axs[i,j].imshow(conv_weights[:,:,i*16+j],vmin=-0.5, vmax=0.5)
    axs[i,j].axis('off')
plt.show()
```

<img width="643" height="100" alt="image" src="https://github.com/user-attachments/assets/dfe93384-d2aa-4f75-aadf-139ce25dfad8" />

```python
# 훈련하지 않은 빈 합성곱 신경망
no_training_model=keras.Sequential()
no_training_model.add(keras.layers.Conv2D(32,kernal_size=3, activation=\relu,
                                          padding='same',input_shape(28,28,1))
                                          )
# 합성곱층 1 변수 저장
no_training_conv=no_training_model.layers[0]
print(no_training_conv.weights[0].shape)
# 평균, 표준편차
no_training_weights=no_training_conv.weights[0].numpy()
print(no_training_weights.mean(), no_training_weights.std())
# 커널 출력
fig, axs=plt.subplots(2,16,figsize=(15,2))
for i in range(2):
  for j in range(16):
    axs[i,j].imshow(no_training_weights[:,:,0,I*16+j],vmin=-0.5, vmax=0.5)
    axs[i,j].axis('off')
plt.show()
```

<img width="652" height="102" alt="image" src="https://github.com/user-attachments/assets/865a9bd4-9bbc-482b-a075-4c1b9f258f7d" />

훈련된 거에 비해 밋밋한 모습 보임<br>

## 함수형 API

Sequential보다 더 복잡한 모델에 사용가능<br>

```python
# dense 층 2개
dense1=keras.layers.Dense(100,activation='sigmoid')
dense2=keras.layers.Dense(10, activation='softmax')
# input 설정
inputs=keras.Input(shape=(784,))
# 호출
hidden=dense1(input)
output=dense2(hidden)
# 연결
model=keras.Model(inputs,outputs)
# input 출력
print(model.input)
# 연결한 새 모델
conv_acti=keras.Model(model.input, model.layers[0].output)
```

## 특성맵 시각화

```python
# 샘플1 그리기
(train_input, train_target),(test_input, test_target)=\
  keras.datasets.fashion_mnist.load.data()
plt.imshow(train_input[0],cmap='gray_r')
plt.show()
# 전처리
inputs=train_input[0:1].reshape(-1,28,28,1)/255.0
feature_maps=conv_acti.predict(inputs)
# 특성맵 그리기
fig, axs=plt.subplots(4,8,figsize=(15,8))
for i in range(4):
  for j in range(8):
    axs[i,j].imshow(feature_maps[0,:,:i*8+j])
    axs[i,j].axis('off')
plt.show()
```

<img width="555" height="278" alt="image" src="https://github.com/user-attachments/assets/1b849801-7252-496c-b26d-61f771ae3365" />

필터와 비교<br>

<img width="645" height="382" alt="image" src="https://github.com/user-attachments/assets/e6f318d4-773c-475c-b454-a28bcc2e101c" />

```python
# 합성곱층 2
conv2_acti=keras.Model(model.inputs, model.layers[2].output)
# 샘플 1 전달
inputs=train_input[0:1].reshape(-1,28,28,1)/255.0
feature_maps=conv2_acti.predict(inputs)
# 그리기
fig, axs= plt.subplots(8,8,figsize=(12,12))
for i in range(8):
  for j in range(8):
    axs[i,j].imshow(feature_maps[0,:,:,i*8+j],vmin=-1,vmax=1)
    axs[i,j].axis('off')
plt.show()
```

<img width="541" height="488" alt="image" src="https://github.com/user-attachments/assets/ae4ba146-ee81-42ba-a630-29c49643a63e" />

합성곱층이 누적될수록 추상적인 정보 학습<br>

