
# Chapter4-2

### 확률적 경사하강법(Stochastic Gradient Descent)

- 훈련세트에서 샘플 하나씩 꺼내 손실함수의 경사에 따라 최적의 모델을 찾는 알고리즘.
- 전체데이터 대신 하나의 데이터 샘플에만 가중치를 업데이트하기 때문에 빠른 학습과 적은 메모리를 사용한다는 장점이 있다.
- 샘플을 선정할때는 전체 데이터중 무작위의 샘플을 선택한다.
- 에포크
    1. 확률적 경사하강법에서 훈련세트를 한번 모두 사용하는 과정, 즉 한번의 전체적인 사이클
- 미니매치 경사하강법
    1. 샘플을 하나씩 선택하는것이 아닌 여러개의 샘플을 사용하여 경사하강법을 수행하는 알고리즘
- 배치경사하강법
    1. 전체 데이터를 이용하여 경사하강법을 수행하는 알고리즘

 

### 손실함수(Loss Function)

머신러닝 모델이 예측한 값과 실제 값 사이의 오차를 측정하는 함수

### 로지스틱 손실함수

로지스틱 회귀모델에서 사용하는 손실함수로 예측값과 실제값 사이의 오차를 최소화하는 방향으로 모델설계가 필요함.

<img width="567" height="432" alt="image" src="https://github.com/user-attachments/assets/da1af6f7-9f15-4b4a-813b-b33a1ceafab1" />


- 여러번의 에포크를 한다고 무조건적으로 좋은것이 아님.
- 너무 적은 에포크일때는 accuracy점수가 높게 나오지 않으며 과소적합될 가능성이 큼
- 너무 많은 에포크일때는 accuracy점수는 높게 나오지만 test set과 train set사이의 정확도가 차이가 많이 나게 된다.
- 적절한 에포크를 찾아 조기종료하는것이 중요함.
